---
title: "Assignment 2"
author: "Jacob Shore & Derek Huang"
date: "February 12, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(infer)
library(skimr)
library(broom)
library(readr)
options(digits=10)
```

# Introduction:
We are interested in examining the relationship between square footage of living space of a house and that corresponding lot's price for properties sold in 2015 in King County, WA (mostly Seattle). Specifically, we are curious if square footage of living space is a good predictor of price for these houses. Our original dataset consisted of 21,613 observations (property sales), but we have randomly selected 1,000 of these observations to be included in the following models, as this should not compromise the relationships between the variables and is less taxing on our computers.

# Analysis

```{r}
set.seed(12897312)
housing2 <- housing[sample(nrow(housing), 1000),]
ggplot(housing2)+geom_point(aes(x = sqft_living, y = price))
# price vs. sqft living

housing_lm <- lm(price ~ sqft_living, data=housing2)
# untransformed model

augment(housing_lm) %>%
ggplot( aes(x=.fitted, y=.std.resid)) +
geom_point() +
geom_hline(yintercept = 0)
# untransformed std. resid. plot


housing_lm2 <- lm(price ~ log(sqft_living), data=housing2)
# transforming X using log (logrithmic model)

augment(housing_lm2) %>%
ggplot( aes(x=.fitted, y=.std.resid)) +
geom_point() +
geom_hline(yintercept = 0)
# transformed log(x) residual


housing_lm3 <- lm(log(price) ~ log(sqft_living), data=housing2)
# transforming both X and Y using log (power model)

housing2 %>%
ggplot(aes(x=log(sqft_living), y=log(price))) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
# transformed data plot

augment(housing_lm3) %>%
ggplot( aes(x=.fitted, y=.std.resid)) +
geom_point() +
geom_hline(yintercept = 0)
# power model residual
```
While the pre-transformed data is certainly linear in nature, it does not have constant variability. In fact, the data is severely heteroskedastic, as errors increase along with the predictor variable (sqft_living). We first tried a logarithmic transformation on the predictor, and while the variance was more stable, residual analysis made it clear that this transformation was introducting unintended curvilinearity into our model. We then tried a power model, tranforming both the predictor and response logarithmically. This model seems to address our concerns, as the data is still linear but now is shown to have constant variance as well. 


```{r}
summary(housing_lm3)
```
The $R^2$ value is 0.4711. This means that 47.11% of the variance in $log(price)$ is explained by a linear relationship with $log(sqft_living)$. The corresponding plot (found above) shows that there is seemingly a strong, positive relationship between $log(price)$ and $log(sqft_living)$, as we expected. In the residual plot, we see constant variability, so we are satisfied with the fit of this model. 

We now run a hypothesis test on the value of $\beta_1$. Our null hypothesis is that $\beta_1 = 0$, and our alternative hypothesis is that $\beta_1 \neq 0$. As shown in the table above, the t-test statistic is 29.82, yielding a p-value of effectively 0. Thus, we may reject the null hypothesis at any reasonable level, and say with confidence that $\beta_1 = 0$ is false, and there is in fact some linear relationship between the logarithm of square footage of living space and the logarithm of price for houses sold in King County in 2015.

```{r}
specific <- data.frame(sqft_living=2000)
mean.int <- exp(predict(housing_lm3, newdata = specific, interval = 'confidence', level = .95))
pred.int <- exp(predict(housing_lm3, newdata = specific, interval = 'prediction', level = .95))
```

We decided to look at predictions for properties with homes that were 2,000 square feet. This is considered a 'standard' size home, perhaps even a large one inside the city (where much of our data comes from). A 95% confidence interval for the mean price of lot with a 2000 sq. ft. house turns out to be (\$470158.8, \$493891.7) -- pretty pricy! For an individual 2000 sq. ft. house, we are 95% confident that the cost will be between (\$222152.5, \$1045261). Again, not particularly reassuring for someone looking to buy a house in Seattle.

```{r, include=FALSE}
crit_val <- qt(.975, glance(housing_lm3)$df.resid)
housing_gl <- broom::glance(housing_lm3)
housing_sig <- dplyr::pull(housing_gl, sigma)

num_int <- 2
crit_Bonf <- qt((1-.975)/num_int, glance(housing_lm3)$df.resid)
crit_WH <- sqrt(2*qf(.95, num_int, glance(housing_lm3)$df.resid))

housing_pred <- broom::augment(housing_lm3) %>%
mutate(.se.pred = sqrt(housing_sig^2 + .se.fit^2)) %>%
mutate(lower_PI = .fitted - crit_val*.se.pred,
upper_PI = .fitted + crit_val*.se.pred,
lower_CI = .fitted - crit_val * .se.fit,
upper_CI = .fitted + crit_val * .se.fit,
lower_PI_Bonf = .fitted - crit_Bonf*.se.pred,
upper_PI_Bonf = .fitted + crit_Bonf*.se.pred,
lower_CI_Bonf = .fitted - crit_Bonf * .se.fit,
upper_CI_Bonf = .fitted + crit_Bonf * .se.fit,
lower_PI_WH = .fitted - crit_WH*.se.pred,
upper_PI_WH = .fitted + crit_WH*.se.pred,
lower_CI_WH = .fitted - crit_WH * .se.fit,
upper_CI_WH = .fitted + crit_WH * .se.fit)
```

```{r}
ggplot(housing_pred, aes(x = exp(log.sqft_living.), y = exp(log.price.))) + geom_point(alpha = .5, col = 'black') +
stat_smooth(method = "lm", se = FALSE) +
geom_ribbon(aes(ymin = exp(lower_PI), ymax = exp(upper_PI)), alpha = .2, linetype = 'solid', col = 'black') +
geom_ribbon(aes(ymin = exp(lower_PI_Bonf), ymax = exp(upper_PI_Bonf)), alpha = .2, col = 'black', linetype = 'dashed') +
geom_ribbon(aes(ymin = exp(lower_PI_WH), ymax = exp(upper_PI_WH)), alpha = .2, col = 'black', linetype = 'dotted')+labs(xlab = "Square Footage of Living Space", ylab = "Price", title = "Back transformed, WH band dotted, Bonf. dashed, normal solid")

ggplot(housing_pred, aes(x = (log.sqft_living.), y = (log.price.))) + geom_point(alpha = .5, col = 'black') +
stat_smooth(method = "lm", se = FALSE) +
geom_ribbon(aes(ymin = (lower_PI), ymax = (upper_PI)), alpha = .2, linetype = 'solid', col = 'black') +
geom_ribbon(aes(ymin = (lower_PI_Bonf), ymax = (upper_PI_Bonf)), alpha = .2, col = 'black', linetype = 'dashed') +
geom_ribbon(aes(ymin = (lower_PI_WH), ymax = (upper_PI_WH)), alpha = .2, col = 'black', linetype = 'dotted')+labs(xlab = "Square Footage of Living Space", ylab = "Price", title = "Untransformed, WH band dotted, Bonf. dashed, normal solid")

ggplot(housing_pred, aes(x = exp(log.sqft_living.), y = exp(log.price.))) + geom_point(alpha = .5, col = 'black') +
stat_smooth(method = "lm", se = FALSE) +
geom_ribbon(aes(ymin = exp(lower_CI), ymax = exp(upper_CI)), alpha = .2, linetype = 'solid', col = 'black') +
geom_ribbon(aes(ymin = exp(lower_CI_Bonf), ymax = exp(upper_CI_Bonf)), alpha = .2, linetype = 'dashed', col = 'black') +
geom_ribbon(aes(ymin = exp(lower_CI_WH), ymax = exp(upper_CI_WH)), alpha = .2, linetype = 'dotted', col = 'black')+labs(xlab = "Square Footage of Living Space", ylab = "Price", title = "Back transformed, WH band dotted, Bonf. dashed, unadj. solid")

ggplot(housing_pred, aes(x = (log.sqft_living.), y = (log.price.))) + geom_point(alpha = .5, col = 'black') +
stat_smooth(method = "lm", se = FALSE) +
geom_ribbon(aes(ymin = (lower_CI), ymax = (upper_CI)), alpha = .2, linetype = 'solid', col = 'black') +
geom_ribbon(aes(ymin = (lower_CI_Bonf), ymax = (upper_CI_Bonf)), alpha = .2, linetype = 'dashed', col = 'black') +
geom_ribbon(aes(ymin = (lower_CI_WH), ymax = (upper_CI_WH)), alpha = .2, linetype = 'dotted', col = 'black')+labs(xlab = "Square Footage of Living Space", ylab = "Price", title = "Untransformed, WH band dotted, Bonf. dashed, unadj. solid")
```

The above plots deal with simultaneous inference. It is important to adjust for multiple comparisons, as it is foolish to think that the intervals returned through standard methods at every point cover their true parameter with probability $(1-\alpha)$. Thus, an adjustment is needed to widen the intervals, given by either Bonferroni's procedure or the Working-Hotelling procedure. The standard method leads to the lower bound on interval size of both procedures, but they introduce greater variance so as to provide greater accuracy while not straying too far from this lower bound.

It is known that the Working-Hotelling procedure outperforms the Bonferroni procedure when larger subsets of the predictor are considered. Since we are examining the entire support of the predictor here, we prefer the WH procedure. The plots also clearly show that the WH band is tighter than the Bonferroni band. Both of these methods are preferred to the unadjusted, however.

# Conclusion

Our analyses have shown that there is a positive, linear relationship between $log(sqft_living)$ and $log(price)$, meaning in general, the bigger the house, the more expensive the lot is. We don't doubt the linearity in the relationship between the untransformed variables, but the heteroskedastic nature makes fitting a linear model a rather suspicious endeavor, as the standard errors will be incorrect. While we suspect that house size is the primary driver of price, it will be interesting to examine how other variables (such as lot size, view, location) drive the price as well, and  in the end, the $R^2$ score of .4711 is notable, but not as strong as we anticipated. It will be interesting to extend this to a multilinear model in the future.